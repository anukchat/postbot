import os
from typing import Dict, Any, TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage, HumanMessage
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from fastapi import HTTPException, Depends
import uuid
from datetime import datetime
import re
from db.sql import get_tweet_by_id
from langgraph.checkpoint.postgres import PostgresSaver
# from langgraph.checkpoint import
# from sqlalchemy import create_engine
# from sqlalchemy.orm import Session
# from db.sql import get_connection_pool
load_dotenv()
from ai.service import get_gemini
import ast

from psycopg import Connection

# Create a global checkpointer instance
DB_URI = "postgresql://postbot:postbot12345@localhost/post_bot?sslmode=disable"
connection_kwargs = {
    "autocommit": True,
    "prepare_threshold": 0,
}
conn=Connection.connect(DB_URI, **connection_kwargs)
checkpointer = PostgresSaver(conn)

class AgentState(TypedDict):
    """Extended state to include thread messages and human intervention flags"""
    tweet: Dict
    tweet_type: list[str] | None
    tags: list
    blog_style: str
    blog_content: str
    status: str
    publication_schedule: Dict[str, Any]
    messages: list[BaseMessage]  # Thread messages
    approval_to_generate: bool
    approval_to_publish: bool
    agent_id: str

class BlogWorkflow:
    def __init__(self, openai_api_key=os.environ["GROQ_API_KEY"]):
        self.llm = get_gemini()
        
        # Define workflow graph
        self.workflow = StateGraph(AgentState)
        
        # Use the global checkpointer
        self.checkpointer = checkpointer
        checkpointer.setup()
        self.graph = self.setup_workflow(self.checkpointer)
        
        # Store active workflows
        self.active_workflows = {}

    def read_prompt(self,prompt_file,**kwargs):

        file_path=os.path.join("src/ai/prompts",prompt_file)
        with open(file_path,'r') as f:
            prompt=f.read()
        
        prompt=prompt.format(**kwargs)

        return prompt
            

    def run_workflow(self, payload: Dict[str, Any], agent_id: str) -> Dict[str, Any]:
        """Synchronous workflow execution"""
        #get old checkpoint if exists
        config = {"configurable": {"thread_id": agent_id}}

        checkpoint=checkpointer.get(config)

        # get tweet data using tweet_id 
        tweet=get_tweet_by_id(payload['tweet_id'])

        if checkpoint is None:
            state=AgentState(tweet=tweet,status="WorkflowInitialized",agent_id=agent_id,messages=[])
            result = self.graph.invoke(state, config)
        else:
            self.graph.update_state(config,values={'approval_to_generate':payload["feedback"]['approval_to_generate'],'blog_style':payload["feedback"]['blog_style']})
            # state["human_feedback"]="yes"feedback
            result = self.graph.invoke(None, config)
        
        return result

    def tweet_classifier(self, state: AgentState) -> Dict:
        """Classify the tweet and update state"""

        classifier_prompt=self.read_prompt("tweet_classifier.txt",input=state['tweet']['full_text'])
        state["messages"].append(HumanMessage(content=classifier_prompt))
        result = self.llm.invoke(state["messages"])
        state["messages"].append(result)
        
        categories = ast.literal_eval(re.findall(r'<category>(.*?)</category>', result.content, re.DOTALL)[0].strip())

        # Simulate classification logic
        # classification = "Informative"  # Example classification
        state["tweet_type"] = categories
        state["status"] = "TweetClassified"

        return state
    

    def blog_ask_from_human(self, state: AgentState) -> Dict:
        """Ask user if they want to create a blog post"""

        if state["approval_to_generate"]:
            state["status"] = "StyleSelection"  # Update the status for blog generation
        else:
            state["status"] = "EndWorkflow"  # Set status to await further feedback
        
        return state

    def style_selection(self, state: AgentState) -> Dict:
        """Ask user to select a blog style"""
        styles = ["Academic", "Conversational", "Technical", "Narrative", "Professional"]
        config = {"configurable": {"thread_id": state['agent_id']}}
        # state["blog_style"]=state["blog_style"]#.graph.update_state(config,values={'blog_style':'Academic'})
        # state['blog_style']="Academic"
        state["status"] = "BlogGeneration"

        return state

    def blog_generator(self, state: AgentState) -> Dict:
        """Generate the blog content"""

        #decode tweet

        for url in state['tweet']['urls']:
            if url['file_category']=='document':
                with open(url['downloaded_path_md'],'r') as f:
                    reference_content=f.read()
                reference_link=url['original_url']
        

        prompt=self.read_prompt('blog_generator.txt',
                                style=state["blog_style"],
                                types=', '.join(state["tweet_type"]),
                                tweet=state['tweet']['full_text'],
                                article=reference_content,
                                references=reference_link
                                )
        
        state["messages"].append(HumanMessage(content=prompt))
        result = self.llm.invoke(state["messages"])
        state["messages"].append(result)
        blog_content=re.findall(r'<blog>(.*?)</blog>', result.content,re.DOTALL)[0]
        tags= ast.literal_eval(re.findall(r'<tags>(.*?)</tags>', result.content, re.DOTALL)[0].strip())
        # Simulate blog content generation
        state["tags"]=tags
        state["blog_content"] = blog_content
        state["status"] = "BlogGenerated"

        return state

    def end_workflow(self, state: AgentState) -> Dict:
        """End the workflow"""
        state["messages"].append(HumanMessage(content="The workflow has ended. Thank you!"))
        return state

    def resume_workflow(self, state: Dict) -> Dict:
        """Resume workflow from saved state"""
        if state["status"] == "AwaitingHumanFeedback":
            state["messages"].append(HumanMessage(content=f"Human feedback: {state['human_feedback']}"))
            return self.tweet_classifier(state)
        elif not state.get("tweet_type"):
            return self.tweet_classifier(state)
        elif not state.get("blog_style"):
            return self.blog_ask_from_human(state)
        elif not state.get("blog_content"):
            return self.blog_generator(state)
        else:
            return self.end_workflow(state)

    def setup_workflow(self, checkpointer):
        """Setup the workflow with nodes and edges"""
        self.workflow.add_node("tweet_classifier", self.tweet_classifier)
        self.workflow.add_node("blog_ask_from_human", self.blog_ask_from_human)
        self.workflow.add_node("style_selection", self.style_selection)
        self.workflow.add_node("blog_generator", self.blog_generator)
        self.workflow.add_node("end_workflow", self.end_workflow)

        self.workflow.add_edge("__start__", "tweet_classifier")
        self.workflow.add_edge("tweet_classifier", "blog_ask_from_human")
        self.workflow.add_edge("blog_ask_from_human","style_selection")
        self.workflow.add_edge("style_selection", "blog_generator")
        self.workflow.add_edge("blog_generator", "end_workflow")
        self.workflow.add_edge("end_workflow", END)

        graph = self.workflow.compile(checkpointer=checkpointer,interrupt_after=["tweet_classifier"],interrupt_before=["style_selection"])
        return graph

def get_workflow() -> BlogWorkflow:
    """Dependency to get a BlogWorkflow instance."""
    return BlogWorkflow()

def main():
    """
    Example usage of the blog workflow
    """
    # Sample tweet data
    sample_tweet = {
        "text": "Exciting new breakthrough in AI language models...",
        "author": "@AIResearcher",
        "url": "https://twitter.com/example/status/123456"
    }
    
    workflow = BlogWorkflow()
    result = workflow.run_workflow(sample_tweet)
    print(result)

if __name__ == "__main__":
    main() 