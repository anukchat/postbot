# Self-Hosting LangGraph: A Scalable AI Solution Explained\n\nFor adults (26-40) seeking to harness the power of AI in a scalable and controlled environment, **self-hosting LangGraph** offers a compelling solution. LangGraph is a framework for building robust, stateful, multi-actor applications with LLMs. The ability to self-host LangGraph means deploying and managing it on your own infrastructure, giving you greater control over your data, security, and costs. This explainer will guide you through the core concepts of LangGraph, its benefits, and how to deploy it effectively, leveraging key components like Redis and Postgres databases for optimal performance. To delve deeper, explore the [LangGraph documentation](https://langchain-ai.github.io/langgraph/how-tos/deploy-self-hosted/).\n\n### Understanding LangGraph\'s Self-Hosted Architecture\n\nWhen deploying LangGraph in a self-hosted environment, understanding the underlying architecture is crucial. **You are responsible for managing the infrastructure, including databases and services.** LangGraph relies heavily on two key components: Redis and Postgres. These are essential for real-time data streaming and persistent storage.\n\n*   **Redis:** This in-memory data store acts as a pub-sub broker. **It enables streaming real-time output from background runs.** LangGraph utilizes Redis to manage queuing and caching operations. Multiple LangGraph deployments can share a Redis instance by using different database numbers within the same instance. For example:\n\n    *   Deployment A: `REDIS_URI` is set to `redis://<hostname_1>:<port>/1`\n    *   Deployment B: `REDIS_URI` is set to `redis://<hostname_1>:<port>/2`\n\n    **It\'s critical that separate deployments do not share the same database number.**\n\n*   **Postgres:** This robust relational database is used for persistent storage. **It stores assistants, threads, runs, persists thread state and long-term memory, and manages the state of the background task queue.** Similar to Redis, multiple self-hosted deployments can share a Postgres instance, but each must use a separate database. For example:\n\n    *   Deployment A: `DATABASE_URI` is set to `postgres://<user>:<password>@/<database_name_1>?host=<hostname_1>`\n    *   Deployment B: `DATABASE_URI` is set to `postgres://<user>:<password>@/<database_name_2>?host=<hostname_1>`\n\n    **Ensure each deployment uses a unique database name to avoid conflicts.**\n\nTo connect to an external Redis database, a connection string is required, including the host, port, database, and any URL parameters. An example of a Redis connection string is:\n\n```\n"redis://langsmith-redis:6379/0"\n```\n\nFor SSL connections, the `rediss://` prefix can be used:\n\n```\n"rediss://langsmith-redis:6380/0?password=foo"\n```\n\nBy configuring an external Redis instance, managing backups and scaling becomes more straightforward. You can configure LangGraph to use an external Redis instance by modifying the `values` file for your LangSmith Helm Chart installation or the `.env` file for your Docker installation. See the [Deployment Options](../../concepts/deployment_options/) for more details.\n\n### Building a LangGraph Docker Image: A Step-by-Step Guide\n\nThis section provides a practical guide on building a Docker image for a LangGraph application.\n\nBefore building a Docker image, ensure your LangGraph application is structured correctly. You can refer to the Application Structure guide for detailed instructions.\n\nHere’s how to build a Docker image for your LangGraph application:\n\n1.  **Prerequisites:**\n\n    *   Ensure you have a working LangGraph application.\n    *   Make sure Docker is installed on your system.\n\n2.  **Install LangGraph CLI:**\n\n    To build the Docker image, you first need to install the LangGraph CLI. Use the following command:\n\n    ```bash\n    pip install -U langgraph-cli\n    ```\n\n3.  **Build the Docker Image:**\n\n    Once the CLI is installed, navigate to your LangGraph application\'s root directory in the terminal. Then, use the `langgraph build` command:\n\n    ```bash\n    langgraph build -t my-image\n    ```\n\n    *   `-t my-image` tags the image with a name (in this case, `my-image`). Choose a relevant name for your image.\n\n4.  **Verify the Image:**\n\n    After the build process completes, verify the image by running:\n\n    ```bash\n    docker images\n    ```\n\n    This command lists all available Docker images, including the one you just built.\n\nWhen running this server, you need to pass three environment variables: `REDIS_URI`, `DATABASE_URI`, and `LANGSMITH_API_KEY`. See the [Environment Variables](#environment-variables) section for more details.\n\n### Environment Variables for LangGraph Deployment\n\nTo successfully deploy LangGraph, you\'ll need to configure several environment variables that dictate how your application connects to its dependencies. These variables provide crucial configuration details for Redis, Postgres, and authentication.\n\nHere’s a breakdown of the essential environment variables:\n\n*   `REDIS_URI`: **This variable specifies the connection details for your Redis instance**. Redis is used as a pub-sub broker, enabling real-time streaming of output from background runs. The value must be a valid [Redis connection URI](https://redis-py.readthedocs.io/en/stable/connections.html#redis.Redis.from_url).\n\n    *   Multiple LangGraph deployments can share a single Redis instance by using different database numbers. For instance, `Deployment A` could use `redis://<hostname_1>:<port>/1`, while `Deployment B` uses `redis://<hostname_1>:<port>/2`. **It\'s crucial that separate deployments do not share the same database number**.\n\n*   `DATABASE_URI`: **This variable contains the connection details for your Postgres database**. Postgres stores assistants, threads, runs, thread state, long-term memory, and manages the background task queue. The value must be a valid [Postgres connection URI](https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING-URIS).\n\n    *   Similar to Redis, multiple deployments can share a Postgres instance by utilizing different databases. For example, `Deployment A` might use `postgres://<user>:<password>@/<database_name_1>?host=<hostname_1>`, and `Deployment B` could use `postgres://<user>:<password>@/<database_name_2>?host=<hostname_1>`. **Ensure that different deployments do not use the same database**.\n\n*   `LANGSMITH_API_KEY`: **Required if you are using [Self-Hosted Lite](../../concepts/deployment_options/#self-hosted-lite)**. This API key is used for one-time authentication when the server starts.\n\n*   `LANGGRAPH_CLOUD_LICENSE_KEY`: **Required for [Self-Hosted Enterprise](../../concepts/deployment_options/#self-hosted-enterprise)**. This license key is also used for a one-time authentication at server startup.\n\n*   `LANGCHAIN_ENDPOINT`: If you\'re sending traces to a [self-hosted LangSmith](https://docs.smith.langchain.com/self_hosting) instance, set this variable to the hostname of your LangSmith instance.\n\nProperly configuring these LangGraph environment variables is crucial for the stability and functionality of your LangGraph deployment. Ensure that all connection strings are accurate and that the necessary databases and instances are running and accessible.\n\n### Running LangGraph Locally with Docker and Docker Compose\n\nTo run a LangGraph application locally, you can use Docker and Docker Compose. This approach simplifies the setup and management of the necessary services, such as Redis and Postgres.\n\nFirst, you\'ll need to have a Docker image of your LangGraph application. If you haven\'t already, you can build one using the LangGraph CLI:\n\n```\nlanggraph build -t my-image\n```\n\nOnce the image is built, you can run it using Docker. **Make sure to replace `my-image` with the actual name you gave to your image.** You\'ll also need to provide appropriate values for `REDIS_URI`, `DATABASE_URI`, and `LANGSMITH_API_KEY` as environment variables.\n\n```\ndocker run \\\n    --env-file .env \\\n    -p 8123:8000 \\\n    -e REDIS_URI="foo" \\\n    -e DATABASE_URI="bar" \\\n    -e LANGSMITH_API_KEY="baz" \\\n    my-image\n```\n\nFor a more streamlined setup, especially if you need to run Redis and Postgres alongside your LangGraph application, Docker Compose is a great option. Here’s a sample `docker-compose.yml` file:\n\n```yaml\nvolumes:\n    langgraph-data:\n        driver: local\nservices:\n    langgraph-redis:\n        image: redis:6\n        healthcheck:\n            test: redis-cli ping\n            interval: 5s\n            timeout: 1s\n            retries: 5\n    langgraph-postgres:\n        image: postgres:16\n        ports:\n            - "5433:5432"\n        environment:\n            POSTGRES_DB: postgres\n            POSTGRES_USER: postgres\n            POSTGRES_PASSWORD: postgres\n        volumes:\n            - langgraph-data:/var/lib/postgresql/data\n        healthcheck:\n            test: pg_isready -U postgres\n            start_period: 10s\n            timeout: 1s\n            retries: 5\n            interval: 5s\n    langgraph-api:\n        image: ${IMAGE_NAME}\n        ports:\n            - "8123:8000"\n        depends_on:\n            langgraph-redis:\n                condition: service_healthy\n            langgraph-postgres:\n                condition: service_healthy\n        env_file:\n            - .env\n        environment:\n            REDIS_URI: redis://langgraph-redis:6379\n            LANGSMITH_API_KEY: ${LANGSMITH_API_KEY}\n            POSTGRES_URI: postgres://postgres:postgres@langgraph-postgres:5432/postgres?sslmode=disable\n```\n\nTo start the application, run:\n\n```\ndocker compose up\n```\n\nThis will spin up LangGraph Deploy on port `8123`. You can verify that the application is running correctly by sending a GET request to the `/ok` endpoint:\n\n```\ncurl --request GET --url 0.0.0.0:8123/ok\n```\n\nIf everything is set up correctly, you should receive a response like this:\n\n```json\n{"ok":true}\n```\n\n### Leveraging External Redis Databases with LangSmith\n\nLangSmith can be configured to connect to an external Redis database for managing queuing and caching operations. **Using an external Redis instance is strongly recommended in a production setting** because it simplifies the management of backups, scaling, and operational tasks.\n\nTo configure LangSmith with an external Redis database, consider the following requirements:\n\n*   **Provision a Redis instance**: Ensure your LangSmith instance has network access to this Redis instance. Managed Redis services like Amazon ElastiCache, Google Cloud Memorystore, or Azure Cache for Redis are recommended.\n*   **Redis Version**: Officially supports Redis versions >= 5.\n*   **Redis Cluster**: Redis Cluster is not supported. Some managed Redis services might use Redis Cluster, but you can connect to a single node within the cluster. For example, Azure Cache for Redis requires a lower tier than `Premium` to avoid Redis Cluster.\n*   **Resource Recommendation**: An instance with at least 2 vCPUs and 8GB of memory is recommended by default, but the actual requirements depend on your tracing workload. Monitor your Redis instance and scale up as needed.\n\nA connection string is required to connect LangSmith to the external Redis database. LangSmith uses `redis-py` to connect to Redis, which supports various connection string formats.\n\nThe connection string should include:\n\n*   Host\n*   Database\n*   Port\n*   URL parameters\n\nThe format is:\n\n```\n"redis://host:port/db?<url_params>"\n```\n\nFor example:\n\n```\n"redis://langsmith-redis:6379/0"\n```\n\nTo use SSL, the `rediss://` prefix can be used. For example:\n\n```\n"rediss://langsmith-redis:6380/0?password=foo"\n```\n\nTo configure LangSmith to use the external Redis instance, modify the `values` file for your LangSmith Helm Chart installation or the `.env` file for your Docker installation.\n\nFor Helm:\n\n```\nredis:\n  external:\n    enabled: true\n    connectionUrl: "Your connection url"\n```\n\nFor Docker:\n\n```\n# In your .env file\nREDIS_DATABASE_URI="Your connection url"\n```\n\nAfter configuring, reinstall your LangSmith instance. If configured correctly, your LangSmith instance will use your external Redis instance. You may also want to explore [Redis implementations for LangGraph](https://github.com/redis-developer/langgraph-redis), offering checkpoint savers and stores functionality.\n\n## Conclusion: Empowering Scalable AI with Self-Hosted LangGraph\n\nIn summary, **self-hosting LangGraph** offers a pathway to scalable AI solutions, granting you greater control over your infrastructure and data. By understanding LangGraph\'s architecture, particularly the roles of Redis and Postgres in managing real-time data and persistent storage, you can effectively tailor your deployment to meet specific needs. Building Docker images using the LangGraph CLI simplifies deployment, while correctly configuring environment variables like `REDIS_URI`, `DATABASE_URI`, and `LANGSMITH_API_KEY` ensures smooth operation. Leveraging external Redis databases, as detailed in the LangSmith documentation [https://docs.smith.langchain.com/self_hosting/configuration/external-redis](https://docs.smith.langchain.com/self_hosting/configuration/external-redis), further enhances scalability and manageability. You might also want to explore [Redis implementations for LangGraph](https://github.com/redis-developer/langgraph-redis) ([https://github.com/redis-developer/langgraph-redis](https://github.com/redis-developer/langgraph-redis)), offering checkpoint savers and stores functionality. Now it\'s time to start experimenting with LangGraph deployments and unlock the potential of scalable AI for your projects. For further reading, consider this guide on setting up Redis as a message queue [https://dev.to/chanh_le/setting-up-redis-as-a-message-queue-a-step-by-step-guide-5gj0](https://dev.to/chanh_le/setting-up-redis-as-a-message-queue-a-step-by-step-guide-5gj0).\n
